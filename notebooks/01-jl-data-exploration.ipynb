{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble.partial_dependence import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_pipeline(df):\n",
    "    \"\"\"\n",
    "    Data pipeline is outlined by the following process:\n",
    "        1) Sort the data by last trip date in ascending order\n",
    "        2) Fill in missing ratings data with the average rating of all riders and drivers respectively\n",
    "        3) Drop the remaining records that contain any sort of missing values (other than ratings)\n",
    "        4) Convert last trip date from pandas object to datetime format\n",
    "        5) Create a \"churn\" column of Boolean value to determine based on our company standards of active users\n",
    "        6) Create column in Boolean value if app user's device is an iPhone\n",
    "        7) Convert luxury car indicator to Boolean\n",
    "        8) Create dummy variables for city\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.sort_values(by=['last_trip_date'])\n",
    "    _fill_na_mean(df, 'avg_rating_of_driver')\n",
    "    _fill_na_mean(df, 'avg_rating_by_driver')\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    df['last_trip_date'] = pd.to_datetime(df['last_trip_date'])\n",
    "    df = _create_indicator(df, 'churn',  df['last_trip_date'] < '2014-06-01')\n",
    "    df = _create_indicator(df, 'phone', df['phone'] == 'iPhone')\n",
    "    df['luxury_car_user'] = df['luxury_car_user'] * 1\n",
    "    df = pd.get_dummies(df, columns=['city'], drop_first=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_variables(df):\n",
    "\n",
    "    X = df.drop(columns = ['signup_date', 'last_trip_date', 'churn'])\n",
    "    y = df['churn']\n",
    "\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def _fill_na_mean(df, column):\n",
    "    df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "\n",
    "def _create_indicator(df, column, condition):\n",
    "    df[column] = condition\n",
    "    df[column] = df[column] * 1\n",
    "    return df\n",
    "\n",
    "def predict_model(X_train, y_train, X_test, model, trees = 100):\n",
    "    if model == LogisticRegression:\n",
    "        model = model(max_iter=1000)\n",
    "    else:\n",
    "        model = model(n_estimators = trees)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    return y_pred, y_pred_proba, model\n",
    "\n",
    "def print_metrics(y_test, y_pred, model_name = 'Model'):\n",
    "    print(model_name, \"- Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "    print(model_name, \"- Precision Score: \", precision_score(y_test, y_pred))\n",
    "    print(model_name, \"- Recall Score: \", recall_score(y_test, y_pred))\n",
    "    print(model_name, \"- F1 Score: \", f1_score(y_test, y_pred, average = 'weighted'))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(\"TP:\", tp, \"  \", \"FN:\", fn, \"  \", \"TN:\", tn, \"  \", \"FP:\", fp)\n",
    "\n",
    "    return\n",
    "\n",
    "# ROC Curve\n",
    "def create_roc_curve(y_test,y_pred_probs1, y_pred_probs2, y_pred_probs3, model1, model2, model3):\n",
    "    fpr1, tpr1, _ = roc_curve(y_test, y_pred_probs1)\n",
    "    auc1 = roc_auc_score(y_test, y_pred_probs1)\n",
    "\n",
    "    fpr2, tpr2, _ = roc_curve(y_test, y_pred_probs2)\n",
    "    auc2 = roc_auc_score(y_test, y_pred_probs2)\n",
    "\n",
    "    fpr3, tpr3, _ = roc_curve(y_test, y_pred_probs3)\n",
    "    auc3 = roc_auc_score(y_test, y_pred_probs3)\n",
    "\n",
    "    plt.figure(1,figsize=(12,8))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr1, tpr1, label=f'{model1} AUC={round(auc1,3)}')\n",
    "    plt.plot(fpr2, tpr2, label=f'{model2} AUC={round(auc2,3)}')\n",
    "    plt.plot(fpr3, tpr3, label=f'{model3} AUC={round(auc3,3)}')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "def plot_feature_importance_chart(model, X):\n",
    "    feature_importance = model.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, np.array(list(X.columns))[sorted_idx])\n",
    "    plt.title('Feature Importance')\n",
    "    fig.tight_layout\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_train = pd.read_csv('../data/churn_train.csv')\n",
    "df0_test = pd.read_csv('../data/churn_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df0_train.copy()\n",
    "df_test = df0_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train = run_data_pipeline(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_variables(df_final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test = run_data_pipeline(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = create_variables(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1, y_pred_proba1, lr_model = predict_model(X_train, y_train, X_test, LogisticRegression)\n",
    "y_pred2, y_pred_proba2, rfc_model  = predict_model(X_train, y_train, X_test, RandomForestClassifier)\n",
    "y_pred3, y_pred_proba3, gbc_model = predict_model(X_train, y_train, X_test, GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred1)\n",
    "print_metrics(y_test, y_pred2)\n",
    "print_metrics(y_test,y_pred3)\n",
    "create_roc_curve(y_test,y_pred_proba1, y_pred_proba2,y_pred_proba3,'LR','RF','GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_chart(gbc_model, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn']=y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>phone</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>luxury_car_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>city_Astapor</th>\n",
       "      <th>city_King's Landing</th>\n",
       "      <th>city_Winterfell</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>4.14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.601011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>5.98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>8.05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.601011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>9.97</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>5.15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.601011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>7.70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.601011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9206</th>\n",
       "      <td>1.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7734</th>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>15.14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.601011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>5.23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_dist  avg_rating_by_driver  avg_rating_of_driver  avg_surge  phone  \\\n",
       "6209      4.14                   5.0              4.601011        1.0      0   \n",
       "8989      5.98                   5.0              5.000000        1.0      1   \n",
       "2680      8.05                   5.0              4.601011        1.0      1   \n",
       "7408      9.97                   5.0              5.000000        1.0      1   \n",
       "3859      5.15                   5.0              4.601011        1.0      1   \n",
       "3866      7.70                   5.0              4.601011        1.0      0   \n",
       "9206      1.10                   4.0              4.000000        1.0      0   \n",
       "7734      0.77                   5.0              3.000000        1.0      1   \n",
       "2225     15.14                   5.0              4.601011        1.0      1   \n",
       "8469      5.23                   5.0              5.000000        1.0      0   \n",
       "\n",
       "      surge_pct  trips_in_first_30_days  luxury_car_user  weekday_pct  \\\n",
       "6209        0.0                       1                0        100.0   \n",
       "8989        0.0                       1                0        100.0   \n",
       "2680        0.0                       1                1        100.0   \n",
       "7408        0.0                       1                0        100.0   \n",
       "3859        0.0                       1                0        100.0   \n",
       "3866        0.0                       1                0        100.0   \n",
       "9206        0.0                       1                0        100.0   \n",
       "7734        0.0                       1                0        100.0   \n",
       "2225        0.0                       1                0        100.0   \n",
       "8469        0.0                       1                0        100.0   \n",
       "\n",
       "      city_Astapor  city_King's Landing  city_Winterfell  churn  \n",
       "6209             1                    0                0      1  \n",
       "8989             0                    0                1      1  \n",
       "2680             0                    0                1      1  \n",
       "7408             0                    0                1      1  \n",
       "3859             1                    0                0      1  \n",
       "3866             0                    0                1      1  \n",
       "9206             1                    0                0      1  \n",
       "7734             0                    0                1      1  \n",
       "2225             0                    0                1      1  \n",
       "8469             0                    1                0      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasql\n",
      "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from pandasql) (1.19.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from pandasql) (1.1.4)\n",
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.3.20-cp39-cp39-macosx_10_14_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.9/site-packages (from pandas->pandasql) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas->pandasql) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.15.0)\n",
      "Building wheels for collected packages: pandasql\n",
      "  Building wheel for pandasql (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26818 sha256=6b11e9c947f47e5afe1e24723ac12478ce1364cd1043c8a6f78bfcd6a7fd852f\n",
      "  Stored in directory: /Users/jl1000260404/Library/Caches/pip/wheels/63/e8/ec/75b1df467ecf57b6ececb32cb16f4e86697cbfe55cb0c51f07\n",
      "Successfully built pandasql\n",
      "Installing collected packages: sqlalchemy, pandasql\n",
      "Successfully installed pandasql-0.7.3 sqlalchemy-1.3.20\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   COUNT(*)\n",
      "0      3292\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT COUNT(*)\n",
    "FROM df\n",
    "WHERE churn = 0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(query,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   COUNT(*)\n",
      "0      6631\n"
     ]
    }
   ],
   "source": [
    "query1 = \"\"\"\n",
    "\n",
    "SELECT COUNT(*)\n",
    "FROM df\n",
    "WHERE churn = 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(query1,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AVG(avg_rating_by_driver)\n",
      "0                   4.792184\n"
     ]
    }
   ],
   "source": [
    "q1 = \"\"\" \n",
    "\n",
    "SELECT AVG(avg_rating_by_driver)\n",
    "FROM df\n",
    "WHERE churn = 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(q1,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AVG(avg_rating_by_driver)\n",
      "0                    4.75711\n"
     ]
    }
   ],
   "source": [
    "q2 = \"\"\" \n",
    "\n",
    "SELECT AVG(avg_rating_by_driver)\n",
    "FROM df\n",
    "WHERE churn = 0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(q2,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AVG(surge_pct)\n",
      "0        8.551742\n"
     ]
    }
   ],
   "source": [
    "q3 = \"\"\" \n",
    "\n",
    "SELECT AVG(surge_pct)\n",
    "FROM df\n",
    "WHERE churn = 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(q3,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AVG(surge_pct)\n",
      "0        9.459143\n"
     ]
    }
   ],
   "source": [
    "q4 = \"\"\" \n",
    "\n",
    "SELECT AVG(surge_pct)\n",
    "FROM df\n",
    "WHERE churn = 0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(q4,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AVG(weekday_pct)\n",
      "0         60.675524\n"
     ]
    }
   ],
   "source": [
    "q5 = \"\"\" \n",
    "\n",
    "SELECT AVG(weekday_pct)\n",
    "FROM df\n",
    "WHERE churn = 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(q5,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AVG(weekday_pct)\n",
      "0         61.979253\n"
     ]
    }
   ],
   "source": [
    "q6 = \"\"\" \n",
    "\n",
    "SELECT AVG(weekday_pct)\n",
    "FROM df\n",
    "WHERE churn = 0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(q6,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Count(*)\n",
      "0       590\n"
     ]
    }
   ],
   "source": [
    "q7 = \"\"\" \n",
    "\n",
    "SELECT Count(*)\n",
    "FROM df\n",
    "WHERE churn = 1 AND `city_King's Landing` = 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(q7,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(*)\n",
      "0      1386\n"
     ]
    }
   ],
   "source": [
    "q8 = \"\"\" \n",
    "\n",
    "SELECT count(*)\n",
    "FROM df\n",
    "WHERE churn = 0 AND `city_King's Landing` = 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(q8,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['avg_dist', 'avg_rating_by_driver', 'avg_rating_of_driver', 'avg_surge',\n",
       "       'phone', 'surge_pct', 'trips_in_first_30_days', 'luxury_car_user',\n",
       "       'weekday_pct', 'city_Astapor', 'city_King's Landing', 'city_Winterfell',\n",
       "       'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = df['last_trip_date'].sort_values(ascending = False)\n",
    "new = df.sort_values(by = ['last_trip_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new.info()\n",
    "new['avg_rating_of_driver'].fillna(new['avg_rating_of_driver'].mean(), inplace = True)\n",
    "new['avg_rating_by_driver'].fillna(new['avg_rating_by_driver'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_trip_date'] = pd.to_datetime(df['last_trip_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn'] = df['last_trip_date'] < '2014-06-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn'] = df['churn'] * 1\n",
    "df['phone'] = df['phone'] == 'iPhone'\n",
    "df['phone'] = df['phone'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['city'], drop_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['luxury_car_user'] = df['luxury_car_user'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['phone'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns = ['signup_date','last_trip_date','churn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(max_iter = 1000)\n",
    "log_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred, labels = [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix = np.array([[tp, fn], [fp, tn]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = log_model.coef_\n",
    "ind = (coeff**2).argsort()\n",
    "labels = [item for item in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "plt.axhline(y=0,color='red')\n",
    "plt.plot(np.linspace(0, 11, 12), coeff.T)\n",
    "ax.set_xticklabels(labels)\n",
    "plt.xticks(np.linspace(0,11,12), rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot()\n",
    "x = np.linspace(0, 11, 12)\n",
    "markerline, stemlines, baseline = plt.stem(x, coeff.T, '-.')\n",
    "plt.setp(baseline, color='r', linewidth=2)\n",
    "plt.xticks(np.linspace(0,11,12), labels,rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Beta Coefficients')\n",
    "plt.title('Feature Impact')\n",
    "plt.grid(linestyle ='--',lw=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "def create_ROC_curve_plot(y_test,y_pred_probs, model):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label=model)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pred_probs = model_pred(X_train, y_train, X_test, y_test, RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_curve_plot(y_test,y_pred_probs, 'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pred_probs = model_pred(X_train, y_train, X_test, y_test, LogisticRegression)\n",
    "ROC_curve_plot(y_test,y_pred_probs, 'LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_curve_plots(y_test,y_pred_probs1, y_pred_probs2, y_pred_probs3, model1, model2, model3):\n",
    "    fpr1, tpr1, _ = roc_curve(y_test, y_pred_probs1)\n",
    "    auc1 = roc_auc_score(y_test, y_pred_probs1)\n",
    "    fpr2, tpr2, _ = roc_curve(y_test, y_pred_probs2)\n",
    "    auc2 = roc_auc_score(y_test, y_pred_probs2)\n",
    "    fpr3, tpr3, _ = roc_curve(y_test, y_pred_probs3)\n",
    "    auc3 = roc_auc_score(y_test, y_pred_probs3) \n",
    "    plt.figure(1,figsize=(12,8))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr1, tpr1, label=f'{model1} AUC={round(auc1,3)}')\n",
    "    plt.plot(fpr2, tpr2, label=f'{model2} AUC={round(auc2,3)}')\n",
    "    plt.plot(fpr3, tpr3, label=f'{model3} AUC={round(auc3,3)}')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1, y_pred_probs1 = model_pred(X_train, y_train, X_test, y_test, LogisticRegression)\n",
    "y_pred2, y_pred_probs2 = model_pred(X_train, y_train, X_test, y_test, RandomForestClassifier)\n",
    "y_pred3, y_pred_probs3 = model_pred(X_train, y_train, X_test, y_test, GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_curve_plots(y_test,y_pred_probs1, y_pred_probs2,y_pred_probs3, 'LR', 'RF','GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_benefit = np.array([[0, 0], [-0.7, 0.3]]).T\n",
    "def profit_curve(cost_benefit, predicted_probs, y_test):\n",
    "    \"\"\"Function to calculate list of profits based on supplied cost-benefit\n",
    "    matrix and prediced probabilities of data points and thier true labels.\n",
    "    Parameters\n",
    "    ----------\n",
    "    cost_benefit    : ndarray - 2D, with profit values corresponding to:\n",
    "                                          -----------\n",
    "                                          | TP | FP |\n",
    "                                          -----------\n",
    "                                          | FN | TN |\n",
    "                                          -----------\n",
    "    predicted_probs : ndarray - 1D, predicted probability for each datapoint\n",
    "                                    in labels, in range [0, 1]\n",
    "    labels          : ndarray - 1D, true label of datapoints, 0 or 1\n",
    "    Returns\n",
    "    -------\n",
    "    profits    : ndarray - 1D\n",
    "    thresholds : ndarray - 1D\n",
    "    \"\"\"\n",
    "    n_obs = float(len(y_test))\n",
    "    # Make sure that 1 is going to be one of our thresholds\n",
    "    maybe_one = [] if 1 in predicted_probs else [1] \n",
    "    all_thresholds = maybe_one + sorted(predicted_probs, reverse=True)\n",
    "    thresholds = all_thresholds[::50]\n",
    "    profits = []\n",
    "    for threshold in thresholds:\n",
    "        y_predict = predicted_probs >= threshold\n",
    "        confusion_matrix_ = confusion_matrix(y_test, y_predict, labels = [1,0])\n",
    "        threshold_profit = np.sum(confusion_matrix_ * cost_benefit) / n_obs\n",
    "        profits.append(threshold_profit)\n",
    "    return np.array(profits), np.array(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_profits(model, cost_benefit, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fits passed model on training data and calculates profit from cost-benefit\n",
    "    matrix at each probability threshold.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model           : sklearn model - need to implement fit and predict\n",
    "    cost_benefit    : ndarray - 2D, with profit values corresponding to:\n",
    "                                          -----------\n",
    "                                          | TP | FP |\n",
    "                                          -----------\n",
    "                                          | FN | TN |\n",
    "                                          -----------\n",
    "    X_train         : ndarray - 2D\n",
    "    X_test          : ndarray - 2D\n",
    "    y_train         : ndarray - 1D\n",
    "    y_test          : ndarray - 1D\n",
    "    Returns\n",
    "    -------\n",
    "    model_profits : model, profits, thresholds\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted_probs = model.predict_proba(X_test)[:, 1]\n",
    "    profits, thresholds = profit_curve(cost_benefit, predicted_probs, y_test)\n",
    "\n",
    "    return profits, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs, thrs = profit_curve(cost_benefit, y_pred_probs3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_thr = thrs[np.argmax(profs)]\n",
    "max_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_profs = np.max(profs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = GradientBoostingClassifier()\n",
    "new_model.fit(X_train, y_train)\n",
    "#print(\" done.\")\n",
    "\n",
    "#print('Convenience plot with ``partial_dependence_plots``')\n",
    "\n",
    "features = [4,7,9,10]\n",
    "fig, axs = plot_partial_dependence(new_model, X_train, features,figsize = (10, 10), \n",
    "                                   feature_names= [item for item in X.columns],\n",
    "                                   n_jobs=3, grid_resolution=50)\n",
    "fig.suptitle('Partial dependence plots')\n",
    "plt.subplots_adjust(top=0.9, bottom = 0.2, wspace = 0.5)  # tight_layout causes overlap with suptitle\n",
    "\n",
    "#print('Custom 3d plot via ``partial_dependence``')\n",
    "#fig = plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
